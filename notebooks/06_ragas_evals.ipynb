{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf439c0a-e7c5-4889-a9ae-e857e6aaf304",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vashi\\anaconda3\\envs\\ragas-eval\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded naive: 50 predictions\n",
      "Loaded enhanced: 50 predictions\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "RAGAs Evaluation for NaiveRAG and then Enhanced RAG\n",
    "\"\"\"\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall\n",
    "from datasets import Dataset\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Setting OPENAI Key\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "if not openai_key:\n",
    "    raise ValueError(\"Set OPENAI_API_KEY environment variable\")\n",
    "os.environ['OPENAI_API_KEY'] = openai_key\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "if not openai_key:\n",
    "    raise ValueError(\"Set OPENAI_API_KEY environment variable\")\n",
    "os.environ['OPENAI_API_KEY'] = openai_key\n",
    "\n",
    "# Load both datasets\n",
    "with open('../results/ragas_naive_data.json', 'r') as f:\n",
    "\tnaive_data = json.load(f)\n",
    "\n",
    "with open('../results/ragas_enhanced_data.json', 'r') as f:\n",
    "\tenhanced_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded naive: {len(naive_data)} predictions\")\n",
    "print(f\"Loaded enhanced: {len(enhanced_data)} predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b854770c-f3f4-43d5-982e-e5bc90001c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "EVALUATING NAIVE RAG\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7564574fba994aecb96cafc1476d87c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[16]: TimeoutError()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m naive_dataset \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_dict({\n\u001b[0;32m      6\u001b[0m \t\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m: [d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m naive_data],\n\u001b[0;32m      7\u001b[0m \t\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m: [d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m naive_data],\n\u001b[0;32m      8\u001b[0m \t\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontexts\u001b[39m\u001b[38;5;124m'\u001b[39m: [d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontexts\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m naive_data],\n\u001b[0;32m      9\u001b[0m \t\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mground_truth\u001b[39m\u001b[38;5;124m'\u001b[39m: [d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mground_truth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m naive_data]\n\u001b[0;32m     10\u001b[0m })\n\u001b[1;32m---> 12\u001b[0m naive_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mnaive_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mfaithfulness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswer_relevancy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_precision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_recall\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ragas-eval\\lib\\site-packages\\ragas\\_analytics.py:277\u001b[0m, in \u001b[0;36mtrack_was_completed.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    276\u001b[0m     track(IsCompleteEvent(event_type\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_completed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m--> 277\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    278\u001b[0m     track(IsCompleteEvent(event_type\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_completed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ragas-eval\\lib\\site-packages\\ragas\\evaluation.py:458\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(dataset, metrics, llm, embeddings, experiment_name, callbacks, run_config, token_usage_parser, raise_exceptions, column_map, show_progress, batch_size, _run_id, _pbar, return_executor, allow_nest_asyncio)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;66;03m# Default behavior: use nest_asyncio for backward compatibility (Jupyter notebooks)\u001b[39;00m\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masync_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_async_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ragas-eval\\lib\\site-packages\\ragas\\async_utils.py:125\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(async_func, allow_nest_asyncio)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Create the coroutine if it's a callable, otherwise use directly\u001b[39;00m\n\u001b[0;32m    124\u001b[0m coro \u001b[38;5;241m=\u001b[39m async_func() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(async_func) \u001b[38;5;28;01melse\u001b[39;00m async_func\n\u001b[1;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoro\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ragas-eval\\lib\\site-packages\\nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ragas-eval\\lib\\site-packages\\nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ragas-eval\\lib\\site-packages\\nest_asyncio.py:115\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m     heappop(scheduled)\n\u001b[0;32m    110\u001b[0m timeout \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m    113\u001b[0m         scheduled[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_when \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime(), \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 115\u001b[0m event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_events(event_list)\n\u001b[0;32m    118\u001b[0m end_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clock_resolution\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ragas-eval\\lib\\selectors.py:324\u001b[0m, in \u001b[0;36mSelectSelector.select\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 324\u001b[0m     r, w, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_writers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ragas-eval\\lib\\selectors.py:315\u001b[0m, in \u001b[0;36mSelectSelector._select\u001b[1;34m(self, r, w, _, timeout)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_select\u001b[39m(\u001b[38;5;28mself\u001b[39m, r, w, _, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 315\u001b[0m     r, w, x \u001b[38;5;241m=\u001b[39m \u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r, w \u001b[38;5;241m+\u001b[39m x, []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[38]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[39]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[40]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[41]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[42]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[43]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[44]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[45]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[46]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[47]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[48]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[49]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[50]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[51]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[52]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[53]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[54]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[55]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[56]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[57]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[58]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[59]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[60]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[61]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[62]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[63]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[64]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[65]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[66]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[67]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[68]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[69]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[70]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[71]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[72]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[73]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[74]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[75]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[76]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[77]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[78]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[79]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[80]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[81]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[82]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[83]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[84]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[85]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[86]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[87]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[88]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[89]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[90]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[91]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[92]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[93]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[94]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[95]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[96]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[97]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[98]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[99]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[100]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[101]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[102]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[103]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[104]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[105]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[106]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[107]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[108]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[109]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[110]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[111]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[112]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[113]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[114]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[115]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[116]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[117]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[118]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[119]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[120]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[121]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[122]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[123]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[124]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[125]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[126]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[127]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[128]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[129]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[130]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[131]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[132]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[133]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[134]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[135]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[136]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[137]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[138]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[139]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[140]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[141]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[142]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[143]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[144]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[145]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[146]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[147]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[148]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[149]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[150]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[151]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[152]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[153]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[154]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[155]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[156]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[157]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[158]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[159]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[160]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[161]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[162]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[163]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[164]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[165]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[166]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[167]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[168]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[169]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[170]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[171]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[172]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[173]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[174]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[175]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[176]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[177]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[178]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[179]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[180]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[181]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[182]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[183]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[184]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[185]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[186]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[187]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[188]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[189]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[190]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[191]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[192]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[193]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[194]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[195]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[196]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[197]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[198]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[199]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[19]: TimeoutError()\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\")\n",
    "print(\"EVALUATING NAIVE RAG\")\n",
    "print(\"\\n\")\n",
    "\n",
    "naive_dataset = Dataset.from_dict({\n",
    "\t'question': [d['question'] for d in naive_data],\n",
    "\t'answer': [d['answer'] for d in naive_data],\n",
    "\t'contexts': [d['contexts'] for d in naive_data],\n",
    "\t'ground_truth': [d['ground_truth'] for d in naive_data]\n",
    "})\n",
    "\n",
    "naive_results = evaluate(\n",
    "\tnaive_dataset,\n",
    "\tmetrics=[faithfulness, answer_relevancy, context_precision, context_recall],\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3ed6b0-fdcc-4b9e-85d8-f293042f8087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the evaluation scores - calculating means from individual metric per question.\n",
    "#Ignoring nans.\n",
    "import numpy as np\n",
    "\n",
    "naive_scores = {\n",
    "\t'faithfulness': np.nanmean(naive_results['faithfulness']),\n",
    "\t'answer_relevancy': np.nanmean(naive_results['answer_relevancy']),\n",
    "\t'context_precision': np.nanmean(naive_results['context_precision']),\n",
    "\t'context_recall': np.nanmean(naive_results['context_recall'])\n",
    "}\n",
    "\n",
    "print(\"\\nNaive RAG Results:\")\n",
    "for metric, score in naive_scores.items():\n",
    "\tprint(f\"  {metric}: {score:.3f}\")\n",
    "\t\n",
    "# Count how many questions actually evaluated\n",
    "valid_count = sum(1 for x in naive_results['faithfulness'] if not np.isnan(x))\n",
    "print(f\"\\nSuccessfully evaluated: {valid_count}/50 questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f86a06d-6553-4c7c-8094-d77f4c6d513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "print(\"EVALUATING ENHANCED RAG\")\n",
    "print(\"\\n\")\n",
    "\n",
    "enhanced_dataset = Dataset.from_dict({\n",
    "\t'question': [d['question'] for d in enhanced_data],\n",
    "\t'answer': [d['answer'] for d in enhanced_data],\n",
    "\t'contexts': [d['contexts'] for d in enhanced_data],\n",
    "\t'ground_truth': [d['ground_truth'] for d in enhanced_data]\n",
    "})\n",
    "\n",
    "enhanced_results = evaluate(\n",
    "\tenhanced_dataset,\n",
    "\tmetrics=[faithfulness, answer_relevancy, context_precision, context_recall],\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7672d9fc-44f1-4aa8-a5b5-c16e5852d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_scores = {\n",
    "\t'faithfulness': np.nanmean(enhanced_results['faithfulness']),\n",
    "\t'answer_relevancy': np.nanmean(enhanced_results['answer_relevancy']),\n",
    "\t'context_precision': np.nanmean(enhanced_results['context_precision']),\n",
    "\t'context_recall': np.nanmean(enhanced_results['context_recall'])\n",
    "}\n",
    "\n",
    "print(\"\\nEnhanced RAG Results:\")\n",
    "for metric, score in enhanced_scores.items():\n",
    "\tprint(f\"  {metric}: {score:.3f}\")\n",
    "\t\n",
    "# Count how many questions actually evaluated\n",
    "valid_count = sum(1 for x in enhanced_results['faithfulness'] if not np.isnan(x))\n",
    "print(f\"\\nSuccessfully evaluated: {valid_count}/50 questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e766ae2b-a07b-437c-924d-dbd61919d016",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame({\n",
    "\t'Metric': ['faithfulness', 'answer_relevancy', 'context_precision', 'context_recall'],\n",
    "\t'Naive RAG': [\n",
    "\t\tnaive_scores['faithfulness'],\n",
    "\t\tnaive_scores['answer_relevancy'],\n",
    "\t\tnaive_scores['context_precision'],\n",
    "\t\tnaive_scores['context_recall']\n",
    "\t],\n",
    "\t'Enhanced RAG': [\n",
    "\t\tenhanced_scores['faithfulness'],\n",
    "\t\tenhanced_scores['answer_relevancy'],\n",
    "\t\tenhanced_scores['context_precision'],\n",
    "\t\tenhanced_scores['context_recall']\n",
    "\t]\n",
    "})\n",
    "\n",
    "comparison['Improvement'] = comparison['Enhanced RAG'] - comparison['Naive RAG']\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"RAGAS COMPARISON\")\n",
    "print(\"\\n\")\n",
    "print(comparison.to_string(index=False))\n",
    "print(f\"\\nNote: Naive evaluated on 14 questions, Enhanced on 7 questions\")\n",
    "\n",
    "comparison.to_csv('../results/06_ragas_comparison.csv', index=False)\n",
    "print(\"Results Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b3c06a-849d-4f8f-aa4e-83833295bd80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
